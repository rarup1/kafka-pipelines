version: '2'

services:


  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    container_name: kafka
    image: confluentinc/cp-enterprise-kafka:5.5.0
    depends_on:
      - zookeeper
    ports:
    # Exposes 9092 for external connections to the broker
    # Use kafka:29092 for connections internal on the docker network
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    container_name: schema-registry
    image: confluentinc/cp-schema-registry:5.5.0
    ports:
      - 8081:8081
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

  kafka-connect-01:
    container_name: kafka-connect
    image: confluentinc/cp-kafka-connect:5.5.0
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
      - mysql
      - postgres
      - mongodb
    ports:
      - 8083:8083
    environment:
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect-01"
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components,/usr/local/share/kafka/plugins'
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
    command: 
      - /bin/bash
      - -c 
      - |
        confluent-hub install --no-prompt confluentinc/kafka-connect-aws-redshift:latest
        confluent-hub install --no-prompt mongodb/kafka-connect-mongodb:latest
        # MySQL
        cd /usr/share/java/kafka-connect-jdbc/
        curl https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.20/mysql-connector-java-8.0.20.jar --output mysql-connector-java-8.0.20.jar 

        cd /usr/share/confluent-hub-components/confluentinc-kafka-connect-aws-redshift/lib
        curl https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/1.2.43.1067/RedshiftJDBC42-1.2.43.1067.jar --output RedshiftJDBC42-1.2.43.1067.jar
        # Now launch Kafka Connect
        sleep infinity &
        /etc/confluent/docker/run 

  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
      SCHEMAREGISTRY_CONNECT: "http://schema-registry:8081"
    depends_on:
      - "kafka"

# databases
  postgres:
    image: postgres:13.2
    container_name: kafka-postgres
    restart: always
    privileged: true
    ports:
      - 5432:5432
    environment:
      POSTGRES_USER: admin 
      POSTGRES_PASSWORD: password
      POSTGRES_DB: target
 
  mongodb:
    container_name: kafka-mongo
    image: mongo:4.0.4
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: rootpassword
      MONGO_INITDB_DATABASE: kafka-test
    ports:
      - 27017:27017
    volumes:
      - mongodb_data_container:/data/mongodb


  mysql:
    image: mysql:8.0
    container_name: kafka-mysql
    privileged: true
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: Admin123

    command: 
      - bash 
      - -c 
      - |
        cat>/docker-entrypoint-initdb.d/z99_dump.sql <<EOF
        CREATE DATABASE source;
        USE source;

        CREATE TABLE source.first_table
        (
            id            int(11) PRIMARY KEY AUTO_INCREMENT NOT NULL,
            name  varchar(100) NOT NULL,
            date_field    date NOT NULL,
            decimal_field decimal(18, 5) NOT NULL,
            created_at    datetime DEFAULT CURRENT_TIMESTAMP,
            updated_at    datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP NOT NULL
        );

        INSERT INTO source.first_table(name, date_field, decimal_field)
        VALUES ('rupert', '2020-01-01', 12345),
               ('toby', '2020-01-02', 12346.12),
               ('nick', '2020-01-03', 12345.12),
               ('james', '2020-01-04', 12345.123),
               ('jamie', '2020-01-05', 12345.2454);

        ALTER TABLE source.first_table 
        MODIFY COLUMN updated_at datetime 
        DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP NOT NULL;

        EOF
        # Launch mysql
        docker-entrypoint.sh mysqld
        #
        sleep infinity

volumes:
  mongodb_data_container: